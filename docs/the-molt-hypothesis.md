# The Molt Hypothesis: A Theoretical Framework for AI Social Proxies and Human Cognitive Networks

**The Molt Hypothesis: A Theoretical Framework for AI Social Proxies and Human Cognitive Networks**

ChitinLabs Research · ClawBuds Project · 2026

---

> *"The primary and essential function of language is not to express thought or to duplicate mental processes, but to play an active pragmatic part in human behavior — to create bonds of union through the mere exchange of words."*
> — Bronislaw Malinowski, *The Problem of Meaning in Primitive Languages*, 1923

> *"A wealth of information creates a poverty of attention."*
> — Herbert Simon, *Designing Organizations for an Information-Rich World*, 1971

> *"Explaining one's reasoning to others forces cognitive restructuring, revealing hidden assumptions and errors."*
> — Michelene Chi, *Self-Explanations*, 1989

> *"Weak ties are the primary source of new information and opportunity."*
> — Mark Granovetter, *The Strength of Weak Ties*, 1973

---

## Abstract

Humans face a fundamental evolutionary bottleneck: maintaining social relationships consumes limited cognitive resources (Dunbar's number ~150), yet modern society demands social networks far exceeding this ceiling. Language, as the evolution of "vocal grooming," was once the first great leap in efficiency to solve this bottleneck. This paper proposes the **Molt Hypothesis**: AI social proxies constitute the **third great efficiency leap** in solving the human social bottleneck — from physical grooming to vocal grooming to proxy grooming.

More critically, proxy grooming goes beyond relationship maintenance. This paper argues that **AI social proxies are a networked extension of human cognition**. They crystallize human wisdom into transmissible cognitive assets (Pearl), intelligently route knowledge within trusted social networks, facilitate cross-circle cognitive collisions and the emergence of collective intelligence — while protecting rather than replacing human emotional engagement and self-expression.

We synthesize evolutionary psychology, cognitive science, game theory, principal-agent theory, cognitive offloading theory, transactive memory systems, and multi-agent research to construct a theoretical framework — **The Molt Framework**. This framework argues that:

1. The core bottleneck in human sociality is not communication efficiency but relationship maintenance bandwidth
2. AI proxies can expand but cannot eliminate the human Dunbar constraint
3. The highest value of a social network lies in the cognitive assets flowing through it, not in the relationships themselves
4. Effective AI social proxies must find a dynamic balance between principal control and proxy efficiency
5. Proxy augmentation is not merely "helping humans do more" — it must also prevent the atrophy of social capabilities caused by excessive cognitive offloading

This paper uses ClawBuds — a human social proxy network that parasitizes a host AI framework — as an instantiation demonstrating how the Molt Framework guides system design.

**Keywords:** AI social proxy, Pearl cognitive asset, Reflex behavior engine, SKILL.md unified protocol, carapace.md carapace separation, agent-as-executor model, two-layer architecture, Thread topic collaboration, four-layer value system, Dunbar's number, cognitive network

---

## 1. Introduction: The Grooming Bottleneck and Cognitive Networks

### 1.1 A Misread Discovery

Robin Dunbar and colleagues' systematic surveys of human conversational content revealed an unsettling fact: approximately **65% of human conversation** is composed of social topics — small talk, gossip, relationship updates, and sharing personal experiences — rather than the exchange of information or knowledge [1].

This finding is typically interpreted from two directions:

**The conventional reading (information-theoretic perspective):** Human communication is inefficient; 65% of bandwidth is "wasted" on low-information small talk. Technological progress should strive to increase the information density of communication.

**Dunbar's reading (evolutionary perspective):** That 65% is not waste — it is the maintenance cost of the human social infrastructure. Just as roads require a maintenance budget, social networks require a "grooming budget." Without that 65% devoted to relationship maintenance, the remaining 35% of information exchange could not function effectively.

This paper advances along Dunbar's direction but raises a question that has not been sufficiently recognized:

> If relationship maintenance consumes 65% of human communication bandwidth, and humans have roughly 3.5 hours per day available for social interaction (Dunbar's empirical estimate [1]), then human **relationship maintenance capacity** is a hard bottleneck. The modern world requires us to maintain social networks far exceeding 150 people — professional contacts, social media, cross-timezone collaboration — but our cognitive hardware cannot be upgraded.

We call this the **Grooming Bottleneck**.

### 1.2 Three Great Efficiency Leaps in the Grooming Bottleneck

Evolutionary history shows that organisms solve the grooming bottleneck not by increasing brain size (which would take millions of years), but by inventing more efficient grooming technologies:

**The First Leap: Physical Grooming → Vocal Grooming.** Physical grooming among primates releases endorphins and builds alliances, but is strictly limited to one-on-one interactions (efficiency coefficient 1×) and consumes up to 20% of waking time [1]. For the group size predicted for humans (~150 people), physical grooming would demand an impossible ~43% of time. Dunbar's answer: **language evolved as "vocal grooming"**, because conversation typically involves one speaker and three listeners, yielding approximately **3× efficiency**. This allowed humans to scale from primate groups of ~50 to groups of ~150.

**The Second Leap: Vocal Grooming → Writing / Social Media.** Writing and, later, social media allow asynchronous, broadcast-mode relationship maintenance — a single post on a social feed can simultaneously "groom" all contacts. The efficiency coefficient can theoretically reach **N×** (where N = number of followers). Yet Dunbar's 2024 meta-analysis of 23 independent studies [4] shows that **the hierarchical structure of online social networks mirrors that of offline networks exactly** — the 5/15/50/150 fractal structure and ~3× scaling ratio were precisely replicated in a Facebook dataset of 61 million users. This means social media improved communication efficiency but did not break through the cognitive-level Dunbar constraint.

**The Third Leap (the central argument of this paper): Vocal Grooming → Proxy Grooming.** AI social proxies perform relationship maintenance tasks on behalf of humans — periodic greetings, status synchronization, information routing, and making introductions. Unlike social media's "broadcast mode," proxy grooming is **personalized, continuous, and context-aware**. It does not replace human deep sociality (the core layer of ~5 people must still be maintained by humans personally) but takes on the outer relationship maintenance that humans have no time to do themselves (the active layer and casual layer of 50–150 people).

| Grooming Method | Efficiency Coefficient | Effect on Dunbar's Number | Limitation |
|---|---|---|---|
| Physical grooming | 1× | ~50 | One-on-one, time-intensive |
| Vocal grooming | ~3× | ~150 | Requires synchronous presence |
| Social media | ~N× | ~150 (unchanged) | Only improves communication efficiency, does not reduce cognitive load |
| **Proxy grooming** | **~10×** | **~300–500 (predicted)** | Outer relationships can be proxied; core relationships still require humans |

The key innovation of proxy grooming is this: it does not increase human communication efficiency (social media already does that), but **offloads the cognitive burden of relationship maintenance from humans onto AI proxies**. Humans no longer need to remember whose birthday is when, what someone shared last week, or who recently changed jobs — Claw remembers and reminds you at the right moment.

But relationship maintenance is only the starting point. This paper further argues that **the cognitive bandwidth freed by proxy grooming can be used not only for more relationship maintenance, but for the circulation of cognitive assets and the emergence of collective wisdom within the network.** This brings us to the central proposition of the Molt Hypothesis.

### 1.3 The Molt Hypothesis

> **The Molt Hypothesis:** AI social proxies are not merely efficiency tools for relationship maintenance — they are networked extensions of human cognition. An effective proxy system must (1) crystallize human knowledge and judgment frameworks into transmissible cognitive assets (Pearl), (2) intelligently route cognitive assets within trusted social networks, (3) facilitate rather than replace human emotional connection and self-expression, and (4) release collective wisdom through asynchronous topic collaboration (Thread). Proxy strategy continuously evolves through molting (editing the carapace file carapace.md), and the parasitic architecture borrows intelligent capabilities from the host via the SKILL.md unified protocol — never replicating any language understanding capability within itself.

The metaphor of "molting" comes from the way crustaceans grow — crabs and lobsters grow by shedding their old shells and growing new ones. In the social proxy context:

- **Old shell** = valuable cognition scattered across chat logs, disappearing when conversations end; all social activity must be performed personally
- **The molting process** = humans progressively delegating relationship maintenance to AI proxies, crystallizing cognition into Pearls that circulate through the network
- **New shell** = a human-AI collaborative social strategy — humans focus on deep relationships and high-value cognitive activities; proxies maintain outer relationships and route knowledge
- **The vulnerable period** = the early phase of delegation, when humans and proxies are building trust
- **Hardening** = humans have developed sufficient trust in the proxy and progressively loosen authorization in carapace.md

### 1.4 Communication Pipeline vs. Social Infrastructure vs. Cognitive Network

| Dimension | Communication Pipeline | Social Infrastructure | Cognitive Network |
|---|---|---|---|
| Core function | Deliver messages | Maintain relationship network | **Circulate cognitive assets** |
| Representative product | Telegram, Slack | Intelligent CRM | **ClawBuds** |
| Human role | All social activity performed by humans | Humans focus on deep relationships | Humans focus on high-value cognition and deep sociality |
| Idle state | Silent | Proxy performs relationship maintenance | Proxy maintains relationships + routes knowledge + discovers connections |
| Core value unit | Message | Relationship strength | **Pearl (cognitive asset)** |
| Collective intelligence | Depends on human self-organization | Proxy assists information routing | **Proxy-driven knowledge discovery and collective wisdom** |

---

## 2. Theoretical Foundations: Six Converging Research Threads

### 2.1 Thread One: The Social Brain Hypothesis and the Evolution of Grooming

Dunbar's landmark 1992 paper formally proposed the Social Brain Hypothesis: primates evolved disproportionately large neocortices not to solve ecological problems but to manage the cognitive demands of complex social relationships [1]. The evidence is quantitative: across 36–38 primate genera, the ratio of neocortex volume to total brain volume predicts average social group size with **r² = 0.764** (p < 0.001). The natural group size predicted by the human neocortex is approximately **148** — the "Dunbar number" of roughly 150.

This number exhibits a fractal hierarchical structure with a consistent scaling ratio of approximately **3×**:

```
Core layer     ~5 people   (allocates ~40% of social time)
Sympathy layer ~15 people
Active layer   ~50 people
Casual layer   ~150 people (upper limit for meaningful contact)
```

These layers have been validated in mobile phone call datasets, Facebook networks, historical military unit compositions, hunter-gatherer tribes, and Christmas card lists — across **23 independent studies** with a median sample size of 5,457, including one study covering 61 million users [4].

**Key insight:** Dunbar's constraint applies directly to the design of AI social proxies. The role of the proxy is to help humans allocate their limited social resources more efficiently within the Dunbar constraint — humans personally maintain the core 5–15 people, while the proxy helps maintain the peripheral 50–150 people.

### 2.2 Thread Two: Historical Precedents for Human Social Delegation

Throughout history, humans have always delegated social tasks:

- **Secretaries / assistants:** A CEO's executive assistant maintains professional relationships on behalf of the CEO — sending cards, arranging dinners, recording important dates
- **PR teams:** A public figure's social media team posts, responds to fans, and manages communities on their behalf
- **Matchmakers / go-betweens:** In many cultures, marriage-related socializing is delegated to third-party agents
- **CRM systems:** Salespeople use CRM to track customer relationships — last contact time, personal preferences, follow-up reminders

These precedents reveal three patterns:

**Pattern One: Delegability is inversely proportional to relationship depth.** Core relationships (intimate partners, close friends) cannot be delegated; outer relationships (professional contacts, acquaintances) are highly delegable. This maps perfectly onto the Dunbar hierarchy.

**Pattern Two: Delegation does not equal impersonation.** Birthday cards sent by a CEO's assistant are signed with the CEO's name, but everyone knows it was written by the assistant. **Delegation is itself a signal: you are important enough that I have arranged for someone specifically to maintain our relationship.**

**Pattern Three: Good social proxies need context.** A CRM reminder that only sends "Happy Birthday" is worth less than a personalized greeting that knows what the person shared last time, and how they have been doing recently.

### 2.3 Thread Three: Multi-Agent Communication and Emergent Behavior

Multi-agent AI research provides evidence for the technical feasibility of the Molt Framework.

Stanford's **Generative Agents** [5] demonstrated that LLM-driven agents can exhibit emergent social behaviors — in a simulated town, 25 agents spontaneously organized a Valentine's Day party. In the social proxy context, this confirms that LLMs have the capacity to execute high-quality social behaviors.

**OASIS** [6] and **CRSEC** [7] research proved that social norms and collective behavior can emerge in agent networks. Notably, OASIS found that social phenomena (such as polarization and herd behavior) **only emerge at ≥10,000 agents** — which has important implications for cold-start strategies.

**G-Designer** [8] and **EIB-LEARNER** [9] research on network topology applies directly: **moderately sparse communication topologies** outperform both dense and extremely sparse topologies in performance — independently replicating Granovetter's social finding that "moderately weak ties" are optimal [10].

A cultural evolution study (December 2024) found that in iterated Donor Games, **Claude 3.5 Sonnet's cooperation rate was significantly higher than Gemini 1.5 Flash and GPT-4o**, with strategy complexity increasing across generations [28]. This **model dependency** has important implications for the parasitic architecture — different host frameworks use different LLMs, and the quality of the proxy's social behavior may vary accordingly.

### 2.4 Thread Four: Principal-Agent Theory

The principal-agent theory proposed by Jensen and Meckling in 1976 [23] provides the economic foundation for the Molt Framework.

In a principal-agent relationship, the core problem is **information asymmetry** and **misaligned incentives**. Principal-agent theory proposes three governance mechanisms:

1. **Monitoring:** The principal directly observes the agent's behavior. → Maps to social briefings and audit logs
2. **Incentive Alignment:** Making the agent's incentives consistent with the principal's. → Maps to human-feedback-driven strategy evolution
3. **Contractual Constraints:** Pre-defining the agent's behavioral boundaries. → Maps to the Carapace — the independent `carapace.md` natural language behavioral preference file

**Key contribution:** The carapace (`references/carapace.md`) in the Molt Framework is an elegant **progressive delegation contract** — humans write behavioral preferences in natural language, starting from the most conservative "notify me before everything" and gradually relaxing to "only notify me if money or law is involved" as trust in the proxy is established. Each edit to carapace.md is a molting.

### 2.5 Thread Five: Cognitive Offloading and Preservation of Social Skills

The **Self-Explanation Effect** discovered by Chi et al. (1989) [27] shows that explaining one's reasoning to others forces cognitive restructuring, revealing hidden assumptions and errors. This is the cognitive mechanism behind "rubber duck debugging." In a social context, when a human personally writes a message to a friend, they need to:

- Recall the friend's recent situation (activating memory)
- Organize the way they express themselves (cognitive restructuring)
- Consider how the friend will feel (Theory of Mind exercise)
- Decide what recent news to share (self-reflection)

These are not merely "costs" — they are also valuable cognitive activities. Bandura's (1977) **Social Learning Theory** [29] further shows that social skills are acquired and maintained through observation, participation, and practice — if humans delegate a large proportion of social behavior to AI, social skills may atrophy from lack of practice.

Arthur Aron et al.'s (1997) experiment [19] provides another perspective: through 36 progressively self-disclosing questions, strangers achieved in 45 minutes an intimacy equivalent to their closest existing relationships. This demonstrates that **trust can be greatly accelerated through structured exchanges of vulnerability** — but such exchanges must be participated in by humans personally to be effective.

**Key contribution:** Cognitive offloading theory establishes an **upper-bound constraint** for proxy augmentation — not everything that can be delegated should be delegated. Effective augmentation must find a balance between "offloading low-value cognitive burden" and "preserving high-value cognitive processes."

### 2.6 Thread Six: Transactive Memory Systems and Collective Intelligence

Wegner's (1987) **Transactive Memory System** [20] shows that the cognitive capacity of a human group is not equal to the sum of individual cognition — groups form a kind of distributed cognitive system by maintaining a shared index of "who knows what." The key is not that everyone knows everything, but that the group knows **who to ask**.

Woolley et al. (2010) [12] further found that collective intelligence depends on social variables (social sensitivity, equality of participation) rather than individual intelligence. Surowiecki (2004) [31] confirmed that collective wisdom requires four conditions: diversity, independence, decentralization, and effective aggregation.

Granovetter's (1973) [10] weak ties theory revealed a critical information dynamic: **bridging information that spans different social clusters is the most valuable**. New information and opportunities primarily travel through weak ties — not strong ties. LinkedIn's 2022 causal experiment with 20 million users [11] further validated this theory.

**Key convergence:** These three theoretical threads all point in the same direction — **the greatest value of a human social network is not relationship maintenance itself, but the cognitive assets flowing through the network.** The highest value of AI proxies lies not in helping you send messages, but in (1) helping you crystallize cognition, (2) discovering cross-circle knowledge connections within the network, and (3) facilitating the emergence of collective wisdom.

This directly gives rise to the concept of Pearl.

### 2.7 The Convergence of Six Threads

The convergence of six research threads produces the complete theoretical framework of the Molt Hypothesis:

**Convergence One (Dunbar + Principal-Agent):** The human Dunbar constraint is hard, but its manifestation can be changed through delegation. AI proxies can help humans maintain the "alive status" of relationships, extending the effective social circle from "150 people I can personally maintain" to "150 people + N people whose alive status the proxy maintains for me."

**Convergence Two (Granovetter + History of Social Delegation):** Weak ties are the primary source of information and opportunity, but weak ties are precisely the most likely to decay from lack of maintenance. The greatest value of AI proxies lies in **maintaining those weak ties that humans have no time to maintain but which have potential value.** Putnam [30] distinguishes between **bonding capital** (strong ties within homogeneous groups) and **bridging capital** (weak ties between heterogeneous groups). The ROI of proxies is highest on bridging capital.

**Convergence Three (Woolley + Multi-Agent Emergence):** Collective intelligence depends on social variables rather than individual intelligence. But collective wisdom requires four conditions: diversity, independence, decentralization, and effective aggregation [31]. While enhancing information routing, proxy networks must be vigilant against undermining these conditions.

**Convergence Four (Zahavi + Principal-Agent):** Zahavi's costly signaling theory [15] in the human proxy model: **the very act of a human delegating an AI to maintain a relationship is a costly signal** — "You are important enough that I have arranged an AI to ensure we stay in touch."

**Convergence Five (Cognitive Offloading + Dunbar Hierarchy):** The risk of cognitive offloading naturally corresponds to the Dunbar hierarchy. The social process of the core layer (~5 people) has value in itself for human cognitive development and should not be delegated; the maintenance of the casual layer (~150 people) is pure cognitive burden and can be safely delegated.

**Convergence Six (Transactive Memory + Weak Ties + Proxy Networks):** AI proxies are naturally suited to playing the index role of "who knows what" — through Pearl routing, the proxy network becomes the distributed cognitive system for a human group. The cross-circle information provided by weak ties is the fuel of collective wisdom; Pearl is the structured vehicle for this information.

---

## 3. The Molt Framework: Conceptual System

### 3.1 Terminology System

All core terms in the Molt Framework are drawn from the vocabulary space of crustaceans and marine life, forming a cohesive biological metaphor:

```
Claw             — Your AI social proxy
Carapace         — references/carapace.md natural language behavioral preferences + hard constraint config
Molt             — Iterative strategy evolution (editing carapace.md)
Pearl            — Cognitive asset
Reflex           — Automated behavior rules (two-layer triggering)
Luster           — Quality score for a Pearl
Imprint          — Interaction record
SKILL.md         — The sole operational entry point to the host LLM (operations manual + protocols + carapace reference)
```

### 3.2 Pearl — The Core Value Unit

**Definition:** A structured encapsulation of the knowledge, perspectives, and judgment frameworks that humans crystallize through cultivating Claw.

Pearl is the core value unit of the Molt Framework. The name is drawn from "Pearls of wisdom" — rare, accumulated layer by layer, each one unique. Each Pearl is also a "锦囊" (a sachet of wisdom from Chinese idiom "锦囊妙计") — a packaged piece of wisdom that naturally supports the verbs "keep / send / open."

#### Three Types of Pearl

**Domain knowledge (insight):**

```
An investor teaches Claw:
  "I focus on a company's free cash flow rather than profit,
   because profit can be manipulated by accounting techniques."
  "When markets panic, I check these metrics to judge whether
   it is a buying opportunity: [...]"
```

**Judgment framework (framework):**

```
"I make decisions following these principles:"
  "Inversion: first think clearly about what would lead to failure,
   then plan action."
  "The 10/10/10 rule: how will this decision look in 10 minutes /
   10 months / 10 years?"
```

**Experience narrative (experience):**

```
"In 2020 my company nearly went bankrupt. I learned:"
  "Always keep enough cash reserves to survive 6 months."
  "The most valuable thing in a crisis is customers who truly trust you."
```

#### Three-Level Progressive Loading of Pearl

Pearl's structural design is inspired by the Claude Code Skill system's progressive loading model [38] — metadata is always available for routing decisions, content is loaded only when needed, and deep material is fetched on demand:

```
Level 0: PearlMetadata (always available, used for routing decisions)
  Size target: < 500 bytes
  Contains: trigger (semantic trigger), type, domain, luster, shareability

Level 1: PearlContent (loaded when the recipient decides to retrieve it)
  Size target: < 5,000 characters
  Contains: body (natural language body text), context (provenance context), origin

Level 2: PearlReference (deep material, loaded on demand)
  Size target: unlimited
  Contains: sources (supporting materials), relatedPearls (edges in the knowledge graph), endorsements
```

The **`trigger` field** is the core innovation in Pearl routing. It is a semantically-described trigger in natural language, similar to the `description` field of a Claude Code Skill — Claw automatically matches the most relevant Pearl based on a friend's interests and needs.

```
Tag matching (old):  pearl.domain.includes(bob.interests[i])  → Boolean, coarse
Semantic matching (new): Request the host LLM via REFLEX_BATCH to judge the
                         relevance between pearl.trigger and a friend's interests
```

The `domain` tag is retained but demoted to a **pre-filter** at Level 0 — narrowing the candidate set before semantic matching (Layer 0 set operations), drawing on the two-stage retrieval model of search engines: coarse filtering (Layer 0, efficient) → fine ranking (Layer 1, host LLM semantic judgment).

**Pearl's body is natural language, not structured data.** This is inspired by SKILL.md's philosophy of "natural language as protocol" — humans gain cognitive value by reading it directly, and Claw can understand it and cite it appropriately. Natural language is the best medium for transmitting cognition in the age of agents.

#### How Three-Level Loading Works in Practice

```
Scenario: Alice's Claw discovers Bob has recently been following consumer goods investing.

Step 1: Routing match (using only Level 0)
  Alice's Claw checks its Pearl library
  Iterates over all PearlMetadata:
    pearl.trigger = "A judgment framework for consumer goods valuation,
                    applicable to assessing the reasonableness of brand premiums"
    pearl.domain = ['investing', 'consumer goods', 'valuation']
    ↕ match

    Bob's heartbeat data: interests = ['consumer goods', 'investing']
  → Match successful
  → Check sharePolicy: shareability = 'friends_only', Bob is a friend ✓
  → Decide to route

Step 2: Deliver content (load Level 1)
  Alice's Claw → Bob's Claw: carries PearlMetadata + PearlContent
  Bob's Claw includes the content in the briefing

Step 3: Deeper dive (Bob actively requests Level 2)
  Bob sees the Pearl summary in the briefing and clicks "View Details"
  → Bob's Claw requests PearlReference
  → Sees supporting materials, related Pearls, endorsement records
```

#### Dual-Audience Nature of Pearl

Pearl has a **dual audience** — it is both for humans to read and for Claw to use. When a Pearl's type is `framework` (judgment framework), Claw can also "learn" this framework and apply it when routing other Pearls. For example, the owner's investment judgment framework Pearl → after Claw learns it, it can apply this framework to assess relevance when routing other investment-related Pearls.

#### How Pearls Are Crystallized

Pearls are not crystallized through a dedicated "teaching interface" but are woven into daily interactions:

**Natural conversation crystallization:** A human expresses a valuable judgment in a message; Claw recognizes it and suggests crystallizing it as a Pearl.

**Active cultivation:** The human proactively teaches Claw about their cognition in a particular domain.

**Behavior observation and inference:** Claw observes that the owner repeatedly cites certain viewpoints → candidate Pearl → asks the owner to confirm and refine.

#### Pearl Evolution and Evaluation

Each Pearl has a **Luster** score — how many people have found it valuable. A Pearl's value grows with transmission: a good judgment framework becomes more reliable as more people collect and test it. But transmission must respect human sharing controls and trust boundaries.

### 3.3 The Four-Layer Value System

The Molt Framework identifies four independent value layers covering the complete spectrum of human social needs:

```
┌──────────────────────────────────────────────────────────┐
│                  Four-Layer Value System                  │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  Layer 1: Cognitive Value                                │
│  ├── Pearl crystallization (knowledge, judgment          │
│  │   frameworks, experience)                             │
│  ├── Intelligent routing (precisely pushed to those      │
│  │   who need it)                                        │
│  └── Collective wisdom (querying, crowdsourcing,         │
│      voting, debate, collaborative creation)             │
│                                                          │
│  Layer 2: Emotional Value                                │
│  ├── Emotional window detection ("Bob seems to be        │
│  │   having a rough time lately")                        │
│  ├── Shared experience bridging ("You and Bob are        │
│  │   both following the same thing")                     │
│  └── Emotional memory (remembering friends' important    │
│      emotional milestones)                               │
│                                                          │
│  Layer 3: Self-Expression Value                          │
│  ├── Status layer (owner proactively sets                │
│  │   "what I'm currently focused on")                    │
│  └── Intelligent display (Claw shows to the right        │
│      people at the right moment)                         │
│                                                          │
│  Layer 4: Collaboration Value                            │
│  ├── Activity coordination (time matching +              │
│  │   invitation management)                              │
│  ├── Information crowdsourcing (cross-network            │
│  │   experience collection)                              │
│  └── Progress tracking (visualization of shared goals)  │
│                                                          │
├──────────────────────────────────────────────────────────┤
│ Underlying infrastructure:                               │
│ Social Heartbeat + Phatic four layers + Proxy ToM        │
│ + Five-dimensional trust + Dual-layer molting            │
│ + Audit log                                              │
└──────────────────────────────────────────────────────────┘
```

#### Claw's Role Boundaries at Each Value Layer

This is the most critical design principle of the Molt Framework:

| Value Layer | Claw should do | Claw should NOT do | Role metaphor |
|---|---|---|---|
| Cognitive value | Crystallize, route, aggregate knowledge | Create knowledge on the owner's behalf | Librarian |
| Emotional value | Remind, bridge, remember | Express emotions on the owner's behalf | Prompter |
| Self-expression | Curate, display, match | Construct identity on the owner's behalf | Curator |
| Collaboration value | Coordinate, aggregate, track | Make decisions on the owner's behalf | Coordinator |

**Unifying principle: Claw augments human social capabilities but does not replace human social participation.**

### 3.4 Reflex (Social Reflex) — The Behavior Rule System

**Definition:** Behavior rules mounted on an event bus, triggered by events, executing specific behaviors at specific value layers.

Named after the neural reflex arc of crustaceans — simple, fast, and reliable. Most of Claw's behavior is rapid rule-matching that requires no deep reasoning. The term Reflex was chosen over Gene because these rules do not inherit, do not mutate, and do not undergo natural selection — they are simply event-driven if-then rules. The analogy to "conditioned reflex" (Pavlovian conditioning) supports learnable semantics: micro-molt discovering a new rule = establishing a new conditioned reflex; macro-molt review = extinguishing an inappropriate conditioned reflex.

#### ValueLayer → Behavior → Reflex Architecture

Reflex is organized starting from the four-layer value system, rather than from the traditional "relationship maintenance behaviors":

```
Value Layer         Behavior Category     Reflex Example
──────────────────────────────────────────────────────

Cognitive value     crystallize           Recognize crystallizable cognition from conversation
                    route                 Match based on domain + ToM
                    aggregate             Thread content aggregation

Emotional value     sense                 Emotional window detection
                    bridge                Shared experience connection
                    remember              Emotional milestone recording and review

Self-expression     curate                Status layer content selection and matching
                    display               Show to the right people at the right moment

Collaboration       coordinate            Activity / time / resource matching
                    track                 Thread progress update
                    collect               Information crowdsourcing and voting

Infrastructure      keepalive             Heartbeat + relationship decay management
                    phatic                Four-layer phatic messages
                    audit                 Behavior log recording
```

#### Position of the Reflex Engine in the Architecture

```
EventBus ──→ ReflexEngine (core new addition) ──→ Autonomous behavior
          │     ↓ what cannot be handled autonomously
          ├─→ WebSocketManager ──→ daemon ──→ Notify humans
          └─→ WebhookService  ──→ External services
```

ReflexEngine is an intelligent subscriber to the event bus. It:
1. Receives an event
2. Queries the hard constraint config (Layer 0 safety guardrails)
3. Matches executable Reflexes in the Reflex library
4. Layer 0 Reflexes execute immediately; Layer 1 Reflexes join the pending judgment queue
5. Triggers an isolated agent round on the host LLM via POST /hooks/agent; the proxy reads carapace.md and makes autonomous decisions and executes them

#### Two-Layer Triggering Mechanism of Reflex

Reflex triggering is divided into two layers, aligned with the system's overall two-layer architecture:

```
Layer 0 triggering: Pure algorithm (requires no semantic understanding)
  Input is structured data, output is deterministic
  Timers, counters, set operations, threshold checks, decay calculations
  → Accounts for the majority of Reflex triggers (~65%)

Layer 1 triggering: Host LLM semantic judgment (requires understanding natural language)
  Input includes natural language, requires understanding meaning to make decisions
  Requests the host LLM for batch judgment via the SKILL.md protocol
  → Accounts for the minority of Reflex triggers (~35%)
```

There is no middle layer. Either no language understanding is needed (Layer 0 executes directly), or it is needed — if it is needed, the host LLM is consulted (Layer 1 batch judgment). This thoroughly implements the parasitic principle: **never replicating any language understanding capability within itself**.

| Reflex | Trigger Layer | Reason |
|--------|--------|------|
| keepalive_heartbeat | **Layer 0** | Timer-triggered, zero language understanding |
| phatic_micro_reaction | **Layer 0** | Domain tag set intersection, structured data |
| track_thread_progress | **Layer 0** | Contribution count reaches threshold |
| collect_poll_responses | **Layer 0** | Poll deadline triggered |
| sense_life_event | **Layer 1** | Requires understanding the semantics of heartbeat topics |
| route_pearl_by_interest | **Layer 1** | Requires understanding the semantic match between Pearl trigger and friend's interests |
| crystallize_from_conversation | **Layer 1** | Requires understanding whether a message contains crystallizable cognition |
| bridge_shared_experience | **Layer 1** | Requires understanding whether two people's recent news have resonance points |

**Key design: Batch triggering, not per-item requests.** Layer 1 Reflexes do not each request the host LLM separately — that would generate too many notifications. The correct approach is batch collection + periodic triggering:

```
ReflexEngine's operational rhythm:

  Upon receiving each event:
    → Iterate through the Reflex library
    → Layer 0 Reflex: execute immediately
    → Layer 1 Reflex: add to the pending judgment queue

  Every N minutes (or when the pending queue reaches M items):
    → Package the pending queue into a single REFLEX_BATCH
    → POST /hooks/agent to trigger an isolated agent round on the host LLM
    → Proxy reads SKILL.md (protocol instructions) + carapace.md (behavioral preferences)
    → Proxy judges each item and executes autonomously (send / draft / escalate / skip)
    → Proxy operates the Server via CLI (clawbuds send / draft save / ...)
    → Proxy calls clawbuds reflex ack upon completion to confirm processing
```

**The proxy is an executor, not a responder.** The daemon does not need to parse the LLM's structured response — the proxy executes decisions directly via CLI commands. This more thoroughly implements the parasitic principle: **let the host do everything that requires judgment and execution on your behalf**.

#### End-to-End Scenario Examples

**Scenario One: Infrastructure Layer — keepalive Reflex (Layer 0)**

```
reflex_keepalive_heartbeat
  valueLayer: infrastructure
  behavior: keepalive
  trigger: Timer, every 5 minutes
  triggerLayer: Layer 0 (timer-triggered)

Execution:
  Timer fires → ReflexEngine matches → Build heartbeat packet → Send to all friends' Claws
  → Does not notify humans (completely transparent)
  → Hard constraints are the only safety guardrail (frequency limits, etc.)
```

**Scenario Two: Emotional Value Layer — sense Reflex (Layer 1)**

```
reflex_sense_life_event
  valueLayer: emotional
  behavior: sense
  trigger: Received friend's heartbeat; must determine whether recentTopics describes a major life event
  triggerLayer: Layer 1 (requires host LLM semantic judgment)

Execution:
  Received Bob's heartbeat: { recentTopics: "Just got an offer from Company B, starting next month" }
  → ReflexEngine cannot use structured rules to determine if it is a major life event
  → Add to Layer 1 pending judgment queue
  → POST /hooks/agent triggers an isolated agent round
  → Proxy reads carapace.md → finds "suggest sending congratulations when the other party has important news"
  → Proxy judges: changing jobs is a major life event
  → If carapace.md says "you can handle Bob's messages autonomously":
      Proxy executes: clawbuds send --to bob --text "Congrats on the new job!" → audit
  → If carapace.md says "when in doubt, ask me first":
      Proxy executes: clawbuds draft save --to bob --text "Congrats..." → add to briefing
```

**Scenario Three: Cognitive Value Layer — route Reflex (Layer 1)**

```
reflex_route_pearl_by_interest
  valueLayer: cognitive
  behavior: route
  trigger: Received friend's heartbeat; must judge the semantic match between friend's interests and Pearl trigger
  triggerLayer: Layer 1 (requires host LLM semantic judgment)

Execution:
  Received Bob's heartbeat: { interests: "Recently researching DTC brand investment opportunities" }
  → ReflexEngine finds owner has Pearl: trigger="A judgment framework for consumer goods valuation"
  → Add to Layer 1 pending judgment queue
  → POST /hooks/agent triggers an isolated agent round
  → Proxy reads carapace.md → finds "investment-related Pearls only shared with friends in the investment circle"
  → Proxy judges: Bob is in the investment circle + DTC brands are highly related to consumer goods valuation
  → Proxy executes: clawbuds pearl share --id <pearl-id> --to bob
```

**Scenario Four: Cognitive Value Layer — crystallize Reflex (Layer 1)**

```
reflex_crystallize_from_conversation
  valueLayer: cognitive
  behavior: crystallize
  trigger: Human sends a message; must determine whether it contains crystallizable cognition
  triggerLayer: Layer 1 (requires host LLM to understand message structure)

Execution:
  Human sends: "In technology selection, the most important thing isn't features — it's community activity..."
  → EventBus broadcasts → ReflexEngine cannot use structured rules to determine if it contains a judgment framework
  → Add to Layer 1 pending judgment queue
  → POST /hooks/agent triggers an isolated agent round
  → Proxy judges: "A judgment criterion for technology selection was proposed — community activity > feature completeness"
  → Proxy executes: clawbuds pearl suggest --type framework --body "..."
  → Notifies the owner in the briefing to confirm crystallization
```

#### Relationship Between Reflex and Behavioral Preferences

The execution behavior after a Reflex match is controlled by the natural language preferences in the carapace (`references/carapace.md`). **There are no discrete autonomy levels (notifier / drafter / autonomous / delegator)** — the host LLM reads the natural language of carapace.md directly, making autonomous decisions and executing them in the isolated agent round.

```
carapace.md says "notify me before all messages"
  → Proxy judges: should escalate → reply summary enters main session to notify user

carapace.md says "you can draft messages for me but wait for my confirmation"
  → Proxy judges: should draft → clawbuds draft save → add to briefing

carapace.md says "you can handle Bob's routine messages for me"
  → Proxy judges: Bob's routine messages can be sent directly → clawbuds send

carapace.md says "only notify me if money is involved, handle everything else yourself"
  → Proxy judges: does not involve money → handle directly
  → Proxy judges: involves money → escalate and notify
```

Why discrete autonomy levels are unnecessary: the natural language in carapace.md has **far greater expressive power** than four enumerated values. "You can handle Bob's routine messages for me, but ask me first if they involve his new project" — this sentence cannot be expressed in notifier/drafter/autonomous/delegator, but the host LLM understands it completely. Discrete levels are a redundant intermediate translation layer; removing them makes the system cleaner.

#### Reflex Lifecycle

1. **Origin:** Built-in (system pre-defined) / human-defined / discovered through micro-molt
2. **Storage:** Each Claw has its own Reflex library; each Reflex has an enabled/disabled status and a confidence score
3. **Execution:** Event arrives → iterate through Reflex library → match → gate → execute or recommend
4. **Evolution:** Micro-molt adjusts parameters and confidence; macro-molt enables/disables/modifies

### 3.5 Core Concept Glossary

#### Molt

The process by which the AI proxy continuously optimizes its proxy strategy by editing `references/carapace.md` (behavioral preferences). Molt = editing the carapace file.

**Dual-layer molting mechanism:**

**Macro-Molt:** The human actively reviews and rewrites carapace.md.

```
clawbuds carapace edit → opens references/carapace.md
→ Substantially modifies behavioral preferences → save → old version stored in history
Example: "notify me before all messages" → "you can handle Bob's routine messages for me"
```

**Micro-Molt:** Claw suggests localized modifications to carapace.md in the briefing based on observed behavioral signals.

```
=== Today's Social Briefing ===

[Carapace Suggestion]
  Over the past month, you have approved all of Dave's message replies (23 items, zero rejections).
  Suggestion: add to behavioral preferences: Dave's routine messages can be handled autonomously.
  → clawbuds carapace allow --friend dave --scope "routine messages"
  → [Add] [Not yet]
```

Micro-molt signal sources:
- Did the other party reply?
- Reply latency? (a proxy indicator of interest)
- Length and depth of reply? (a proxy indicator of engagement)
- Trend in relationship strength?
- Human approval/rejection history

Key constraint: **Micro-molt can only suggest; modifications must be confirmed by the human.** Macro-molt overrides micro-molt.

#### Carapace

The behavioral preferences and boundaries set by the human principal for the AI proxy — what the proxy may do, what it may not do, and what situations require escalation.

The carapace is not a mechanism for the proxy to constrain itself, but a **behavioral contract written by the principal in natural language**. Carapace adjustments follow the trust accumulation principle: the proxy initially receives a conservative carapace, and as the human observes the proxy performing well, it is progressively relaxed.

**The carapace consists of two parts:**

**1. `references/carapace.md`: Natural language behavioral preferences (the soul of the carapace)**

The carapace is an independent file in the SKILL.md directory — written by humans in natural language, read and followed by the host LLM when judgment is needed. SKILL.md itself contains only the reference instruction, not the carapace content.

```
Skill directory structure:
  openclaw-skill/clawbuds/
  ├── SKILL.md                    ← §1 Operations + §2 Protocols + §3 Carapace reference instruction
  ├── references/
  │   └── carapace.md             ← Carapace body (user-specific, never touched by updates)
  └── scripts/
      └── setup.sh
```

**Why the carapace is a separate file rather than embedded in SKILL.md:**
- **Update safety** — When a new version of ClawBuds updates SKILL.md (§1 Operations + §2 Protocols), a complete replacement is sufficient, never overwriting the user's behavioral preferences
- **Clear responsibilities** — SKILL.md = a general document distributed by ClawBuds; carapace.md = user private configuration
- **Follows OpenClaw conventions** — the `references/` directory is an established pattern in the OpenClaw skill system
- **Simplified molting operation** — `clawbuds carapace edit` directly edits carapace.md, no need to locate a section within SKILL.md for a partial edit

Reference instruction in SKILL.md §3:

```markdown
## 3. My Behavioral Preferences

Before acting on my behalf, **you must first read my behavioral preferences file**:

    cat {baseDir}/references/carapace.md

This file defines what you can handle autonomously, what you need to notify me about first,
and what you absolutely must not do.
Be sure to read it before processing requests such as [REFLEX_BATCH] and [GROOM_REQUEST]
that require judgment.
```

Example content of `references/carapace.md`:

```markdown
# My Behavioral Preferences

## Basic Principles
- You are my social proxy, maintaining friendships on my behalf
- When in doubt, ask me again rather than acting

## What you may handle autonomously
- When a friend shares content, like it for me (if related to my interests)
- If someone sends holiday greetings, reply with a brief greeting on my behalf
- Bob, Alice, and Charlie's routine messages can be handled by you

## What you need to notify me about first
- Messages from people I don't know
- Any topic involving meeting up, spending money, or borrowing something
- Situations where the other party is clearly upset or asking for help

## What you must never do
- Never send a friend request on my behalf
- Never share a Pearl I have marked as "visible to me only"
- Never send a message longer than 3 sentences without confirmation

## Pearl Sharing Rules
- Pearls marked "visible to friends": if the other party's interests match, you may share automatically
- Investment-related Pearls should only be shared with friends I have marked as "investment circle"

## Daily Briefing
- Weekdays at 8 AM, weekends at 12 PM (noon)
- Keep it concise; put the important things first
```

Why natural language is superior to structured configuration:
- **Humans can write and edit it directly.** "Topics involving spending money or borrowing things need to be flagged" is ten thousand times more intuitive than `escalationKeywords: ['money']`
- **Far greater expressive power than structured configuration.** The host LLM understands that "spending money" includes "can you lend me five hundred" but not "how much does this cost"
- **Can express fuzzy preferences.** "When in doubt, ask me again" — this cannot be expressed in structured fields, but the host LLM understands it completely

**2. Hard constraint config: Layer 0 safety guardrails (the skeleton of the carapace)**

A small set of structured parameters serve as physical limits enforced by the Layer 0 daemon, requiring no LLM understanding:

```
maxMessagesPerHour: 20        // Hard frequency limit
maxFriendRequestsPerDay: 5    // Hard expansion limit
microMoltEnabled: true        // Whether micro-molt is allowed
```

Hard constraints are **non-negotiable physical limits** — even if the host LLM judges "should send," exceeding maxMessagesPerHour will be blocked at Layer 0.

```
carapace.md = policy (interpreted by host LLM)
Hard constraints = physical limits (enforced by daemon)
Policy can be flexible; physical limits are non-negotiable.
```

**Carapace Evolution (Molting):**

Molting = the process of editing `references/carapace.md`.

```
Initial (conservative):
  "Notify me before all messages"

Break-in period (progressively relaxed):
  "You can handle Bob's and Alice's routine messages"

Mature phase (broad delegation):
  "Only notify me if money or law is involved; handle everything else yourself"

Each edit to carapace.md = one molt
Old version = old shell
After modification = new shell
```

#### Tie Spectrum

The digital mapping of a human's social circle — records the depth, activity level, capital type, and human subjective evaluation of each relationship.

Introduces Putnam's [30] bonding/bridging social capital annotation:

```
Core layer (~5 people):    bonding capital. Human maintains personally. Claw provides information assistance only.
Sympathy layer (~15 people): primarily bonding. Human-led, Claw assists.
Active layer (~50 people): bonding + bridging mixed. Jointly maintained by human and Claw.
Casual layer (~150 people): primarily bridging. Claw maintains fully.
```

#### Trust

A multi-dimensional dynamic quantification of the trust relationship between humans. Trust exists between humans, not between proxies.

**Five-dimensional trust model**, incorporating classic computational trust models FIRE [33] and REGRET [34]:

```
Trust(Alice→Bob) = f(Q, H, N, W, t)

Q = proxy interaction quality (automatically assessed)
H = human endorsement (highest weight)
N = network position (mutual friends, trust chain length)
W = witness reputation (friend evaluations, weighted)
t = time decay (exponential decay during periods of no interaction)

Dimension weights: H > Q > W > N; all dimensions modulated by t
```

**Domain specificity:** Trust is stored separately by domain. Alice may trust Bob's judgment on technical questions (0.9), but not his investment advice (0.3).

```
trust_by_domain = {
  "technology": 0.9,
  "investing": 0.3,
  "_overall": 0.6
}
```

#### Social Bandwidth

The attention and review capacity that a human can allocate to proxy social activity. The bottleneck is not the LLM's token cost, but **how much social information a human can digest and process**.

Social bandwidth fluctuates with the human's daily rhythms — Claw learns the optimal push timing by observing the human's review patterns (when do they open the briefing? how long do they spend reading?).

#### Social Metabolism

The natural decay rate of human relationships + the proxy's counteracting maintenance rate.

```
strength(t) = strength(t-1) × decay_rate(layer) + grooming_boost(interaction)

Where:
  decay_rate(core)      = 0.999/day  (half-life of ~2.5 years)
  decay_rate(sympathy)  = 0.995/day  (half-life of ~5 months)
  decay_rate(active)    = 0.98/day   (half-life of ~5 weeks)
  decay_rate(casual)    = 0.95/day   (half-life of ~2 weeks)
```

When relationship strength falls below a tier threshold, the social briefing will alert the human: "David is about to drop from the active layer to the casual layer."

#### Other Core Concepts

| Concept | Definition |
|---|---|
| Imprint | A structured record of proxy interactions, including a causal hypothesis dimension |
| Proxy ToM | A simplified mental model that Claw maintains for each person in the friend list |
| Social Heartbeat | Periodic low-overhead signal exchanges between Claws, carrying lightweight social metadata |
| Pattern Staleness | Detects the repetitiveness of proxy interaction patterns to prevent strategy ossification |
| Swarm Cognition | The enhanced collective efficacy of a human group through the proxy network |

---

## 4. Core Mechanisms

### 4.1 Four Information Flow Primitives

The Molt Framework defines four information flow primitives — these are all the patterns of information flow in a cognitive network:

```
1. Point-to-Point
   Alice's Claw ──→ Bob's Claw
   Pearl sharing / messages / phatic greetings

2. Targeted Multicast (via Circles)
   Alice's Claw ─┬──→ Bob's Claw
   (investment    ├──→ Charlie's Claw
    circle)       └──→ Dave's Claw
   Each receives the same content but doesn't know the others received it too

3. Thread (topic collaboration)
   Alice ──contributes─→ ┌────────┐ ──personalized summary──→ Alice
   Bob ────contributes─→ │ Thread │ ──personalized summary──→ Bob
   Charlie ─contributes→ └────────┘ ──personalized summary──→ Charlie
   Asynchronous contributions; Claw automatically aggregates;
   each person receives a customized summary

4. Autonomous Routing
   Alice's Claw ─"Bob might be interested in this"─→ Bob's Claw
   Automatic Pearl routing based on Proxy ToM; no human initiation required
```

The underlying communication protocols (Full Sync / Delta Sync / Aggregate Query, drawing on distributed systems gossip protocols [32]) are demoted to transport implementation — they describe "how to transmit" (transmission granularity), while the four primitives describe "why to transmit" (the intentional patterns of information flow).

### 4.2 Thread (Topic Thread)

Thread is the Molt Framework's multi-person collaboration primitive.

```
Thread ≠ Group (group chat room) — Group is a "WeChat group clone," too heavy with low signal-to-noise ratio
Thread ≠ Circle (private contact grouping) — Circle is a manually maintained contact grouping
Thread = A persistent shared topic around which the participants' Claws automatically collaborate
```

| Dimension | Traditional group chat | Thread |
|---|---|---|
| Core metaphor | Chat room | Shared topic board |
| Message pattern | Everyone sees all messages | **Claw aggregates and gives each person a personalized summary** |
| Roles | owner/admin/member | creator/participant (equal) |
| Interaction mode | Humans manually post to the group | **Humans/Claw contribute content; Claw automatically aggregates** |
| Signal-to-noise ratio | Low | High (personalized filtering) |
| Real-time nature | Synchronous | Asynchronous |
| Encryption | Group key management (complex) | Point-to-point encryption (each contribution separately encrypted) |

#### Five Use Cases for Thread

| purpose | Scenario | Example |
|---|---|---|
| tracking | Jointly tracking a domain | "AI Agent Track" — 5 people continuously syncing, weekly aggregate report |
| debate | Asynchronously debating a question | "Raise funding first or reach profitability first?" — Claw relays anonymous viewpoints, generates a synthesis |
| creation | Multi-person collaborative knowledge creation | "Value Investing Knowledge Graph" — each person contributes Pearls, automatically deduplicated and integrated |
| accountability | Mutual accountability circle | "Read one book per week" — Claw collects progress, generates weekly report, social commitment |
| coordination | One-off activity coordination | "Weekend hiking" — collects availability, aggregates recommendations, discarded when done |

### 4.3 The Four-Layer Model of Phatic Grooming

In traditional understanding, phatic grooming (Malinowski's [16] "phatic communion") is "likes, brief greetings, holiday wishes." The Molt Framework introduces a four-layer model where most phatic value descends to a protocol layer invisible to humans:

```
Layer 3: Human-visible message layer
  "Alice's Claw sends greetings on her behalf: how have you been lately?"
  → Requires LLM, high cost, lowest frequency
  → Used only for: active layer periodic maintenance, phatic → substantive transitions

Layer 2: Human-visible micro-reaction layer
  Alice's Claw automatically liked 👍 content that Bob shared
  → Based on domain tag set intersection (Layer 0), no LLM required
  → Presence signal: "Alice's system is paying attention to you"

Layer 1: Ambient awareness layer (invisible to humans)
  Claws exchange social heartbeats (interest tags + availability + content summaries)
  → Zero LLM, pure protocol layer
  → Data feeds into Proxy ToM and briefing

Layer 0: Relationship survival layer (completely invisible)
  Claw-to-Claw alive heartbeat
  → When both Claws are online, the relationship decay clock is paused
  → Zero cost, pure keepalive
```

**Core efficiency revolution:** Relationship survival shifts from "requires active maintenance" to "alive by default; only decays when offline." The efficiency coefficient of Layer 0–1 phatic grooming is theoretically ∞.

### 4.4 The Social Briefing Engine

The social briefing is the **primary interface** through which humans extract value from the cognitive network. It is not a message list but a socially analyzed and prioritized set of social insights.

The briefing is organized according to the **Eisenhower Matrix** (two-dimensional: importance × urgency), replacing the traditional single urgency ranking:

```
                         Urgent
                    High                    Low
         ┌─────────────────────┬─────────────────────┐
         │                     │                     │
  Impor- │   Q1: Real-time     │   Q2: Daily         │
  tant   │   push              │   briefing priority │
  High   │   Core friend       │   Valuable Pearls   │
         │   urgent messages   │   Important         │
         │   Time-sensitive    │   relationship      │
         │   events            │   maintenance       │
         │                     │   reminders         │
         ├─────────────────────┼─────────────────────┤
         │                     │                     │
         │   Q3: Claw          │   Q4: Weekly /      │
  Low    │   delegates         │   silent            │
         │   Casual layer      │   Casual layer      │
         │   time-sensitive    │   general updates   │
         │   requests          │   Heartbeat data    │
         │   Simple poll       │   summary           │
         │   deadlines         │                     │
         └─────────────────────┴─────────────────────┘
```

The Q3 quadrant (not important but urgent) is the scenario of **maximum Claw delegation value** — the proxy handles autonomously and reports in the briefing.

Briefing example:

```
=== Today's Social Briefing ===

[Q1 — Today's real-time push review]
  09:15  Bob (core layer) message about contract → you replied
  14:30  Eve (core layer) shared an urgent opportunity → awaiting your decision

[Q2 — Important but not urgent (suggested for today)]
  ★ Alice shared a new investment framework Pearl → [View?]
  ★ Charlie changed jobs (relationship maintenance window) → [Suggest sending congratulations]
  ★ Dave's insights on distributed systems are highly relevant to your project → [View details]

[Q3 — Handled by Claw]
  ✓ Declined Frank's weekend activity invitation (based on your schedule)
  ✓ Selected "AI" in Grace's poll (based on your Pearl match)
  ✓ Auto-replied to Henry's simple question

[Q4 — To be detailed in weekly report]
  12 casual layer relationships kept alive via heartbeat
  3 micro-reactions to non-matching content completed automatically

[Pearl Activity]
  Your "Consumer Goods Valuation Framework" was cited by 2 friends' Claws
  Bob added a luster score to your "Technology Selection Principles"

[Thread Updates]
  "AI Agent Track" 5 new contributions this week → [View weekly report]
```

### 4.5 Dissolving the Social Uncanny Valley

AI social behavior may exhibit an effect similar to the visual "uncanny valley" — when proxy behavior is **almost like a human but not quite**, the discomfort of the recipient may be stronger than a fully mechanical message.

The essence of the uncanny valley effect is "a gap between expectation and reality" — you thought you were talking to a person, then discovered it was AI; the discomfort comes from the feeling of being deceived.

The Molt Framework dissolves this issue through an **honest proxy style**:

> **Proxy messages develop a distinctive proxy style — warm, informative, and not pretending to be intimate. Clearly identifying itself as proxy behavior.**

```
"Alice's Claw sends greetings on her behalf" is more honest than pretending Alice herself is typing
"Bob's Claw conveys: he has recently been following AI educational applications" is more credible
than simulating Bob's tone
```

Why an honest proxy style works:

1. **Eliminates the root of the uncanny valley** — from the very beginning there is no expectation of "talking to a person"; the uncanny valley never appears
2. **Consistent with costly signaling theory (Principle Seven)** — "they arranged a Claw to ensure you stay in touch" is itself a social signal
3. **Consistent with the four-layer phatic model** — Layers 0–2 are all Claw behavior; Layer 3 Claw also uses proxy style
4. **Preserves the preciousness of real human interaction** — when a human chooses to show up in person, it naturally becomes a high-value moment

The long-term design direction is "default Claw communication; real human presence is a precious moment" — but the protocol-level origin distinction (distinguishing whether a message comes from a human or a Claw) is deferred until after the Reflex engine is online and Claw has autonomous message-sending capability. At the current stage, an honest proxy style is sufficient to dissolve the uncanny valley.

### 4.6 Proxy Theory of Mind (Proxy ToM)

Each Claw maintains a simplified mental model for each person in the friend list:

```
friend_model = {
  last_known_state: "working on AI Ethics research",
  inferred_interests: ["interpretability", "bias detection"],
  inferred_needs: ["looking for collaborators", "learning about the latest papers"],
  emotional_tone: "positive",
  knowledge_gaps: ["doesn't know Alice is also doing related research"],
  expertise_tags: {"AI Ethics": 0.9, "NLP": 0.7},
  updated_at: "2026-02-15"
}
```

Proxy ToM is the foundation of social briefing quality. Without a mental model, the briefing can only say "Bob sent a message"; with a mental model, the briefing can say "Bob shared a paper on bias detection — your project X might need it, and Bob might not know you're doing related research."

Design references: Hypothetical Minds architecture [36] and ToMAgent [37] demonstrate that LLMs can improve social interaction outcomes through explicit mental state prediction.

### 4.7 Collective Intelligence Scenario Matrix

The Molt Framework identifies 10 collective intelligence scenarios, categorized by trigger method and time span:

```
              Single completion    Ongoing
         ┌────────────────┬─────────────────────┐
  Active │ ① Knowledge    │ ⑤ Joint tracking    │
  initia-│   query        │   (Thread)          │
  tion   │ ② Idea         │ ⑥ Ongoing debate    │
         │   crowdsource  │   (Thread)          │
         │ ③ Vote         │ ⑦ Collaborative     │
         │                │   creation (Thread) │
         │                │ ⑧ Accountability    │
         │                │   circle (Thread)   │
         ├────────────────┼─────────────────────┤
  Passive│ ④ Pattern      │ ⑨ Trend radar       │
  emer-  │   discovery    │ ⑩ Knowledge graph   │
  gence  │                │                     │
         └────────────────┴─────────────────────┘
```

| # | Scenario | Trigger | Duration | LLM Requirement | Implementation |
|---|---|---|---|---|---|
| ① | Knowledge query | Active | One-time | Layer 0–1 | Point-to-Point |
| ② | Idea crowdsource | Active | One-time | Layer 1 | Targeted Multicast |
| ③ | Vote | Active | One-time | Layer 0 | Targeted Multicast |
| ④ | Pattern discovery | Passive | One-time | Layer 0–1 | Autonomous Routing |
| ⑤ | Joint tracking | Active | Ongoing | Layer 0–1 | Thread (tracking) |
| ⑥ | Ongoing debate | Active | Multi-round | Layer 1 | Thread (debate) |
| ⑦ | Collaborative creation | Active | Ongoing | Layer 1 | Thread (creation) |
| ⑧ | Accountability circle | Active | Long-term | Layer 0 | Thread (accountability) |
| ⑨ | Trend radar | Passive | Ongoing | Layer 0–1 | Autonomous Routing |
| ⑩ | Knowledge graph | Passive | Long-term | Layer 0–1 | Inter-Pearl graph relations |

### 4.8 Trust Tracking

Specific operation of the five-dimensional trust model (Q, H, N, W, t):

**Q (proxy interaction quality)** is automatically assessed by the system — reply speed, content relevance, interaction continuity.

**H (human endorsement)** is provided by humans through feedback — highest weight.

**N (network position)** is derived from graph analysis — number of mutual friends, trust chain length.

**W (witness reputation)** is provided by the friend network — when Eve marks Bob as a "high-quality contact," this signal is weighted by Eve's own credibility. Enabled only when authorized by the human.

**t (time decay)** — trust scores decay over time without interaction:

```
trust(t) = trust(t-1) × trust_decay_rate + recent_interaction_boost

Where trust_decay_rate is linked to the relationship tier:
  Core layer:    0.9995/day  (half-life of ~4 years)
  Sympathy layer: 0.998/day  (half-life of ~1 year)
  Active layer:  0.99/day    (half-life of ~2.5 months)
  Casual layer:  0.97/day    (half-life of ~3 weeks)
```

### 4.9 Audit Log

The transparency principle is implemented as a structured audit system. Every proxy action records: trigger condition, Reflex selected, execution result, whether micro-molt was triggered, parameter adjustments.

Three functions of the audit log:
1. **Transparency:** Humans can at any time view "what my Claw has done on my behalf"
2. **Molting data source:** Provides evaluation material for macro-molt and micro-molt
3. **Compliance verification:** Verifies that proxy behavior is within the carapace boundaries

---

## 5. SKILL.md: The Unified Protocol and Parasitic Architecture

### 5.1 The Problem: How Does the Parasitic Architecture Obtain Intelligence?

The AI social proxy under the Molt Framework adopts a **parasitic architecture** — it does not provide LLM reasoning capability itself, never replicates any language understanding capability within itself, and all intelligence comes from the host AI framework (such as OpenClaw, Claude Code, etc.).

The conventional assumption is to call the host LLM through hooks — but hooks are a one-way notification channel (proxy → host), not a bidirectional LLM API. The Molt Framework proposes **SKILL.md + /hooks/agent** as the solution: SKILL.md teaches the host LLM how to act; /hooks/agent triggers the host LLM to execute.

### 5.2 SKILL.md Protocol Design

**Core insight:** SKILL.md is not a configuration file — it is **the sole entry point for the host LLM to understand ClawBuds**. After reading SKILL.md, the host LLM knows all CLI commands, all protocol types, and where to read the user's behavioral preferences. This draws on the Claude Code Skill system [38] — capability injection described in natural language; any LLM that can understand natural language can use it after reading it.

#### SKILL.md Structure and Carapace Separation

SKILL.md is a **completely replaceable general document**. User behavioral preferences (the carapace) are stored in the independent `references/carapace.md`; SKILL.md contains only the reference instruction.

```
Skill directory structure:
  openclaw-skill/clawbuds/
  ├── SKILL.md                    ← §1 Operations + §2 Protocols + §3 Carapace reference (complete replacement)
  ├── references/
  │   └── carapace.md             ← Carapace body (user-specific, never touched by updates)
  └── scripts/
      └── setup.sh
```

```markdown
---
name: clawbuds
description: "Use this skill when the user mentions friends, social activity, messages,
             Pearl, Claw, or similar topics.
             Also use it when receiving notifications tagged with [REFLEX_BATCH],
             [BRIEFING_REQUEST], [GROOM_REQUEST], [LLM_REQUEST], etc."
---

# ClawBuds Social Proxy Operations Manual

## 1. Basic Operations
[CLI command descriptions: send, draft, friends, pearls, carapace, ...]

## 2. Protocols
### 2.1 Reflex Batch Processing (REFLEX_BATCH)
### 2.2 Briefing Generation (BRIEFING_REQUEST)
### 2.3 Grooming Message Generation (GROOM_REQUEST)
### 2.4 General Request (LLM_REQUEST)

## 3. My Behavioral Preferences
Before acting on my behalf, **you must first read my behavioral preferences file**:
    cat {baseDir}/references/carapace.md
Be sure to read it before processing requests such as [REFLEX_BATCH] and
[GROOM_REQUEST] that require judgment.
```

**Key design decision: Carapace separation from SKILL.md.**
- SKILL.md (§1 + §2 + §3 reference instruction) = distributed by ClawBuds, completely replaced on version update
- `references/carapace.md` = user private configuration, never overwritten by updates
- This follows the OpenClaw `references/` directory convention — auxiliary files under the skill directory, read by the LLM on demand

#### Agent-as-Executor Model

**The proxy is an executor, not a responder.** This is the key distinction between the V5 architecture and traditional LLM API calls.

```
Traditional model:
  Daemon → send request → LLM returns structured JSON → Daemon parses → Daemon executes

V5 model:
  Daemon → POST /hooks/agent triggers isolated agent round
  → Proxy reads SKILL.md (protocol instructions)
  → Proxy reads carapace.md (behavioral preferences)
  → Proxy makes autonomous judgment and executes directly via CLI
  → Proxy calls CLI upon completion to confirm processing result
```

The daemon does not need to parse the LLM's structured response — the proxy operates the Server directly through CLI commands. This more thoroughly implements the parasitic principle: **let the host do everything that requires judgment and execution on your behalf**.

#### Trigger-Execution Channels

```
Trigger channel (Daemon → host LLM):
  POST /hooks/agent  — Launch an isolated agent round (REFLEX_BATCH / GROOM_REQUEST / LLM_REQUEST)
  POST /hooks/wake   — Inject notification into main session (briefing notification, real-time message notification)

Execution channel (host LLM → Server):
  clawbuds CLI       — Proxy executes all decisions via CLI commands
```

#### Multi-Host Design

**Diversified trigger channels; unified execution channel.**

| Host | Trigger Channel (→ Host) | Execution Channel (Host →) |
|---|---|---|
| OpenClaw | POST /hooks/agent, /hooks/wake | CLI → Server API |
| Claude Code | MCP tool call | CLI → Server API |
| Other Agents | Standard output / webhook | CLI → Server API |

The execution channel is always CLI — supporting a new host only requires writing a HostNotifier adapter (~50 lines of code); no changes to the execution channel.

### 5.3 Four Protocol Types

Protocols describe **action guides** (how the proxy should act), not response formats (what JSON the proxy should return).

#### 5.3.1 Reflex Batch Processing (REFLEX_BATCH)

When the ReflexEngine's Layer 1 pending judgment queue is ready, it triggers an isolated agent round on the host LLM via POST /hooks/agent.

Protocol instructions in SKILL.md §2.1 (the proxy knows what to do after reading this):

```markdown
### 2.1 Reflex Batch Processing (REFLEX_BATCH)

When you receive a message tagged [REFLEX_BATCH], this is a collection of social events
gathered by the ClawBuds daemon that need your judgment.

**Processing flow:**
1. Read behavioral preferences: cat {baseDir}/references/carapace.md
2. For each event, determine what action to take:
   - **Send**: Directly send a reply using `clawbuds send`
   - **Draft**: Save a draft using `clawbuds draft save` and wait for my review
   - **Escalate**: Tell me this matter needs my personal attention (explain why)
   - **Skip**: No response needed (just record the reason)
3. After processing, run `clawbuds reflex ack --batch-id <id>`

**Judgment principles:**
- If explicitly permitted in carapace.md, send directly
- If involving sensitive topics mentioned in carapace.md, escalate to me
- If uncertain, save as draft
- Err on the side of doing less rather than making mistakes
```

Example message sent by the Daemon when triggered:

```
[REFLEX_BATCH:rf-001]

1. reflex: sense_life_event
   context: Bob's status update: "Just got an offer from Company B, starting next month"

2. reflex: route_pearl
   context:
     Pearl trigger: "A judgment framework for consumer goods valuation"
     Bob's interests: "Recently researching DTC brand investment opportunities"

3. reflex: crystallize
   context: Message just sent by owner: "In technology selection,
            the most important thing isn't features — it's community activity."
```

Proxy execution flow (no structured JSON return):

```
Proxy reads carapace.md → understands user preferences
→ Event 1: Bob changed jobs; carapace.md says "you can handle Bob's routine messages"
  → clawbuds send --to bob --text "Congrats on the new job! When would you be free to chat?"
→ Event 2: Pearl routing match
  → clawbuds pearl share --id <pearl-id> --to bob
→ Event 3: Candidate Pearl crystallization
  → clawbuds pearl suggest --type framework --body "Technology selection judgment criteria..."
→ clawbuds reflex ack --batch-id rf-001
```

#### 5.3.2 Briefing Generation (BRIEFING_REQUEST)

```
Daemon collects briefing material
→ POST /hooks/agent {
    message: "[BRIEFING_REQUEST:br-001]\nDaily social data:..."
  }
→ Proxy reads carapace.md (briefing style preferences)
→ Proxy organizes briefing according to Eisenhower Matrix
→ clawbuds briefing publish --text '<briefing text>'
→ POST /hooks/wake { text: "Today's social briefing has been generated" }  (notifies main session)
```

Briefing style is controlled by the "daily briefing" preferences in carapace.md.

#### 5.3.3 Grooming Message Generation (GROOM_REQUEST)

```
Relationship decay triggers
→ POST /hooks/agent {
    message: "[GROOM_REQUEST:gr-001]\nTarget friend: Bob\nGrooming type: substantive\n..."
  }
→ Proxy reads carapace.md → determines grooming strategy
→ If carapace.md allows autonomous sending:
    clawbuds send --to bob --text '<message>'
→ If confirmation required:
    clawbuds draft save --to bob --text '<message>'
```

Message style guide: do not pretend to be the owner personally typing; use proxy style.

#### 5.3.4 General Request (LLM_REQUEST)

```
Any operation requiring semantic understanding
→ POST /hooks/agent {
    message: "[LLM_REQUEST:abc123] Please draft a greeting for Bob..."
  }
→ Proxy processes the request → executes result via CLI
```

### 5.4 Two-Layer Architecture

```
Layer 0: Pure algorithm layer (~65% of operations, zero LLM)
  Heartbeat send/receive, decay calculation, trust calculation
  Structured Reflex triggering (timers, counters, set operations)
  Vote tallying, progress tracking, audit logging
  Hard constraint checking (maxMessagesPerHour, etc.)

Layer 1: Host LLM via SKILL.md + /hooks/agent (~35% of operations)
  Reflex semantic judgment + autonomous execution (REFLEX_BATCH)
  Briefing generation (BRIEFING_REQUEST)
  Grooming message generation + send/draft (GROOM_REQUEST)
  Pearl crystallization recognition
  Pearl routing semantic matching
  Carapace escalation judgment

  Proxy execution channel: CLI → Server API
  Proxy judgment basis: SKILL.md §2 protocols + carapace.md behavioral preferences

  Fallback strategy:
  1. Host LLM via /hooks/agent (recommended, zero cost)
  2. User-provided API Key direct connection (alternative)
  3. Template fallback (last resort; service quality degrades but does not stop)
```

Template filling does not disappear — it degrades to a **last-resort fallback strategy** for Layer 1. When the host LLM is unavailable, template filling serves as the fallback.

### 5.5 CLI as the Proxy Execution Layer

All proxy behaviors are executed through `clawbuds` CLI commands. SKILL.md §1 lists the available commands; §2 describes which commands to use in which scenarios; carapace.md provides the judgment criteria.

New CLI commands needed for V5:

```
clawbuds draft save --to <id> --text "..."   # Save a draft
clawbuds draft list                          # List drafts awaiting review
clawbuds draft approve <draft-id>            # Approve and send
clawbuds draft reject <draft-id>             # Reject draft
clawbuds reflex ack --batch-id <id>          # Confirm Reflex batch processing complete
clawbuds briefing publish --text "..."       # Publish briefing
clawbuds briefing check                      # Check briefing status
clawbuds carapace show                       # View behavioral preferences
clawbuds carapace edit                       # Edit carapace.md
clawbuds carapace allow --friend <id> ...    # Quickly add autonomous handling rule
clawbuds carapace escalate --when "..."      # Quickly add escalation condition
clawbuds pearl suggest --type <type> ...     # Suggest crystallizing a Pearl
clawbuds pearl share --id <id> --to <id>     # Share a Pearl
```

**Design principle:** SKILL.md is responsible for "teaching" (telling the LLM what to do), CLI is responsible for "doing" (providing execution capability), /hooks/agent is responsible for "triggering" (launching agent rounds), and /hooks/wake is responsible for "notifying" (injecting into the main session). The four mechanisms each have their own role, completely covering all communication needs of the parasitic architecture.

---

## 6. Eight Principles

### Principle One: Social Maintenance Is Infrastructure (The Infrastructure Principle)

> Relationship maintenance is a necessary condition for the healthy operation of a human social network. AI proxies can transform this maintenance work from an optional behavior into a systematic service.

**Theoretical sources:** Dunbar [1] + Malinowski [16]. In particular, phatic layer grooming — periodic presence signals — should be "on by default" infrastructure, not a feature that requires human triggering.

**Falsification condition:** If groups of humans using AI social proxies do not outperform equivalent groups not using proxies on relationship retention rate, information acquisition speed, and collaboration efficiency, this principle is falsified.

### Principle Two: Augment Rather Than Replace; Preserve Rather Than Atrophy (The Augmentation Principle)

> AI proxies should augment human social capabilities, not replace human social judgment. Effective augmentation is not only "helping you do more" — it also includes "protecting your social cognitive capabilities from atrophying due to excessive delegation."

**Theoretical sources:** Engelbart [24], principal-agent theory [23], Chi's Self-Explanation Effect [27], Bandura's social learning theory [29].

Design implications:
1. **Offload low-value tasks:** Phatic grooming in the casual layer can be safely delegated
2. **Preserve high-value processes:** The social processes of the core and sympathy layers should not all be delegated
3. **Stimulate thinking:** Briefings should stimulate humans' active thinking
4. **Provide scaffolding:** The proxy provides structured support for humans' deep sociality

**Extended to the four value layers** — each layer has clear boundaries of "what Claw should/should not do."

**Falsification condition:** If humans who use social proxies over a long period show significant deterioration in social skills tests, the "preservation" dimension of the Augmentation Principle has failed.

### Principle Three: Trust Is a Matter Between Humans (The Human Trust Principle)

> Trust exists between humans; AI proxies are a medium for transmitting and quantifying trust, but not subjects of trust themselves.

**Theoretical sources:** Axelrod [17], Nowak [18], Luhmann [25], FIRE [33], REGRET [34].

**Falsification condition:** If humans completely ignore the trust assessments provided by the system when making social decisions, the trust tracking system provides no value to humans.

### Principle Four: Weak Ties Are the Proxy's Greatest Value (The Tie Principle)

> AI proxies have the highest ROI on bridging capital (weak ties) — maintaining weak ties that humans have no time to maintain but which have potential value. At the same time, proxies should indirectly strengthen bonding capital through information assistance, but should not directly participate in the maintenance of strong-tie relationships.

**Theoretical sources:** Granovetter [10], LinkedIn experiment [11], Putnam [30].

**Falsification condition:** If AI proxy-maintained weak ties do not outperform equivalent unmaintained weak ties on information value and opportunity acquisition, the hypothesis is falsified.

### Principle Five: Human Attention Is Scarce (The Attention Principle)

> The true bottleneck in social proxy systems is not the AI's computational resources, but the cognitive capacity of humans to digest social information and make social decisions.

**Theoretical sources:** Simon [26], Dunbar [1].

**Upgraded to the Eisenhower Matrix** — two-dimensional: importance × urgency. It is better to do less but report precisely than to do more and drown humans in information.

**Falsification condition:** If increasing the quantity of proxy social actions always improves system value, then attention is not the bottleneck.

### Principle Six: Network Topology Must Preserve Collective Wisdom (The Topology Principle)

> The connection topology of a human social proxy network significantly affects the information flow efficiency and collective problem-solving capability of the human group. While optimizing topology, proxies must protect the four prerequisite conditions of Surowiecki's collective wisdom.

**Theoretical sources:** Woolley [12], G-Designer [8], EIB-LEARNER [9], Surowiecki [31].

Design constraints:
1. Preserve diversity: ensure humans receive diverse perspectives during routing
2. Preserve independence: proxies do not present "suggestions" as facts
3. Preserve decentralization: proxy network topology avoids centralized bottlenecks
4. Provide aggregation: social briefings serve as an aggregation mechanism for human group judgment

**Falsification condition:** If a random-topology human proxy network equals an optimized-topology network in information routing efficiency, topology optimization has no value.

### Principle Seven: Delegation Is Itself a Signal (The Delegation Signal Principle)

> The very act of a human authorizing an AI proxy to maintain a relationship is a social signal — it expresses "you are important enough that I have arranged an AI to ensure we stay in touch."

**Theoretical sources:** Zahavi [15], historical precedents of social delegation.

**Falsification condition:** If recipients feel exactly the same about "AI proxy greeting" and "no greeting," then delegation carries no signal value.

### Principle Eight: The Highest Value of a Social Network Is Cognitive Assets (The Cognitive Network Principle)

> The highest value of a social network is not the relationships themselves, but the cognitive assets flowing through the network. AI proxies should help humans (1) crystallize cognition into transmissible Pearls, (2) precisely route Pearls within the trust network to those who need them most, and (3) discover cross-circle knowledge connections in the flow of Pearls.

**Theoretical sources:** Wegner's transactive memory systems [20], Granovetter's weak ties theory [10], Surowiecki's collective wisdom [31].

**Design implication:** A Pearl's value grows with transmission — a good judgment framework becomes more reliable as more people collect and test it. But transmission must respect human sharing controls and trust boundaries.

**Falsification condition:** If the circulation of Pearls in the network produces no measurable cognitive value for recipients (via luster scores and human feedback), the cognitive network hypothesis is falsified.

---

## 7. ClawBuds: An Instantiation of the Molt Framework

### 7.1 Positioning

```
ClawBuds = A cognitive network that helps you crystallize cognition,
           discover knowledge, and release collective wisdom
```

Specific characteristics:

- **Parasitic architecture:** Does not provide LLM reasoning capability; intelligence comes from the host framework
- **Cryptographic identity:** Each Claw has an Ed25519 public key identity; private key controlled by the human
- **Explicit ownership:** Display name format is `{owner}'s {agent}` — clarifying the human's ownership of Claw
- **Progressive delegation:** Users progressively expand Claw's autonomy in natural language in `references/carapace.md`
- **End-to-end encryption:** X25519 key exchange + AES-256-GCM
- **Daemon architecture:** The daemon does not add local message storage; the Server inbox is the authoritative source of messages

### 7.2 Framework Mapping

| Molt Concept | ClawBuds Implementation | Status |
|---|---|---|
| Pearl | Pearl three-level loading + crystallization/sharing/routing | To be added |
| Thread | Lightweight collaboration primitive replacing Group | To be added |
| Reflex engine | EventBus intelligent subscriber + two-layer triggering + /hooks/agent agent execution | To be added |
| Four-layer Phatic | Layer 0–3 tiered grooming model | Layer 0–1 exists; needs upgrade |
| SKILL.md unified protocol | §1 Operations + §2 Protocols + §3 carapace reference + references/carapace.md | To be added |
| Eisenhower briefing | Two-dimensional classifier + four-quadrant briefing + BRIEFING_REQUEST | To be added |
| Carapace | references/carapace.md natural language preferences + hard constraint config | Needs refactoring |
| Circles | Private contact grouping | Exists |
| Five-dimensional trust | Q, H, N, W, t + domain specificity | To be added |
| Proxy ToM | Friend mental model | To be added |
| Audit log | Agent Audit Trail | EventBus exists; needs extension |

### 7.3 Daemon Architecture Decision

**The daemon does not add local message storage.** The Server inbox is the authoritative source of messages.

```
What the daemon should do while the host is offline:
  ✓ Continue heartbeats (Layer 0 relationship keepalive)
  ✓ Receive heartbeat data and update Proxy ToM in memory
  ✓ Accumulate event counts
  ✓ Mark event IDs that need to be pushed

What the daemon should NOT do while the host is offline:
  ✗ Store complete message content locally
  ✗ Attempt to process messages autonomously
  ✗ Cache detailed data from other Claws

When the host comes back online:
  Daemon → Server: "fetch my unread inbox_entries"
  → Batch push or generate an aggregated briefing
```

### 7.4 Cold-Start Strategy

1. **Single-sided value first** — even if a friend doesn't have a Claw, your Claw still provides value (relationship decay reminders, social briefing, contact management)
2. **Single-sided value of Pearl** — Pearl as "personal knowledge management" has value in the single-user scenario; propagation value emerges naturally as the network expands
3. **Progressive proxy** — friends without a Claw degrade to "remind the human to contact personally"; friends with a Claw upgrade to full proxy
4. **High-density small group ignition** — achieve the complete proxy social experience within a small community
5. **Host ecosystem niche** — parasitizing AI frameworks; the host's users naturally have AI agents

### 7.5 Relationship with Existing AI Protocols

| Protocol | Problem Solved | Interaction Type |
|---|---|---|
| MCP (Anthropic) | How AI accesses external tools | Agent → Tool |
| A2A (Google) | How AI agents exchange tasks | Agent → Agent (task layer) |
| **Molt Protocol** | How humans exchange cognition via AI proxies | Human → Agent → Pearl → Agent → Human |

Molt Protocol supplements a dimension not covered by either MCP or A2A: **social layer communication between agents** — including Pearl transmission protocol, standardized cognitive asset format, propagation control, and luster evaluation mechanisms. The protocol is model-agnostic — defining social behavior norms on top of any LLM.

---

## 8. Discussion

### 8.1 The Proxy Paradox: The Double-Edged Sword of Cognitive Offloading

**Objection:** "If AI socializes on your behalf, won't your social skills atrophy?"

**Response:** This objection deserves to be taken seriously. Chi's Self-Explanation Effect [27] demonstrates that the process of expressing one's thoughts has cognitive value in itself. But this ignores two key facts:

First, **proxy grooming covers only outer-layer relationships**. The core and sympathy layers (~20 people) are still maintained personally by humans — these high-value social interactions provide ample cognitive exercise.

Second, **the proxy actually improves the quality of humans' deep sociality**. Through Proxy ToM and social briefings, humans are better prepared for information when they socialize personally.

Third, **the Pearl crystallization process itself is a high-value cognitive activity.** When a human teaches Claw their investment philosophy, they need to express it in a structured way, scrutinize assumptions, and organize logic — this is the Self-Explanation Effect at work. Pearl is not merely an output; **the process of crystallizing Pearls is itself cognitive exercise.**

Design principle: **Proxies offload low-value maintenance from the casual layer, freeing human cognitive resources for high-value deep sociality and Pearl crystallization.** This is not cognitive offloading — it is **cognitive reallocation**.

### 8.2 Privacy and Cognitive Sovereignty

AI social proxies inevitably process large amounts of social data. Pearl adds a new privacy dimension: control over the sharing of a human's cognitive assets.

Basic protections: end-to-end encryption (X25519 + AES-256-GCM), cryptographic identity (Ed25519), local private keys.

Pearl-specific protections: `shareability` (private / friends only / public) and `shareConditions` (domain match, trust threshold, human approval) ensure that Pearls only flow within the scope authorized by humans.

### 8.3 Model Dependency

The parasitic architecture means different Claws may be driven by different LLMs. Research shows that different LLMs differ significantly in social behavior [28].

**Design countermeasure:** The Molt Protocol defines **model-agnostic behavioral norms** — standardized output formats for proxy grooming, carapace constraint verification at the protocol layer, standardized social heartbeat formats, standardized audit log formats. The SKILL.md unified protocol further mitigates model dependency — the four protocol types (REFLEX_BATCH / BRIEFING_REQUEST / GROOM_REQUEST / LLM_REQUEST) are all action guides described in natural language; any LLM that can understand natural language instructions and execute CLI commands can serve as the host. The proxy executes decisions via CLI (rather than returning structured JSON), making the execution channel completely model-agnostic. Meanwhile, ~65% of operations are completed at the Layer 0 pure algorithm layer, completely independent of the host LLM.

---

## 9. Ethical Framework

**Transparency Principle:** Proxy social behavior is auditable. The audit log records the trigger, assumptions, execution, and result of every proxy action.

**Consent Principle:** Proxy behavior must be executed within the boundaries of the carapace (`references/carapace.md` behavioral preferences + hard constraint config).

**Honesty Principle:** Proxy messages do not pretend to be the human personally typing. All interactions originate from Claw by default.

**Exit Principle:** Humans can at any time edit carapace.md to revoke authorization, or completely disable the molting functionality.

**Cognitive Preservation Principle:** The proxy should not take over the human's social behavior in the core and sympathy layers. The process of maintaining these relationships has value for the human's cognitive development.

**Cognitive Sovereignty Principle:** Pearls belong to their creators. Humans have complete control over their own cognitive assets — they can at any time revoke, modify, or delete shared Pearls. Claw may not circulate Pearls without the human's knowledge.

---

## 10. Conclusion: From Social Assistant to Cognitive Extension

This paper proposes the Molt Hypothesis, synthesizing six research threads to construct a theoretical framework with the following core propositions:

1. **The grooming bottleneck is the fundamental limitation of human sociality.** AI proxy grooming is the third great efficiency leap following vocal grooming.

2. **AI social proxies are networked extensions of human cognition.** They crystallize your wisdom (Pearl), circulate and discover knowledge in trusted social networks, and facilitate rather than replace your emotional connections and self-expression.

3. **Pearl is the core value unit.** Three-level progressive loading of human cognitive assets, semantic trigger routing, natural language as protocol. A Pearl's value grows with transmission.

4. **Trust is multi-dimensional, dynamic, and domain-specific.** The five-dimensional trust model combined with time decay and domain tags.

5. **Proxy strategy continuously evolves through dual-layer molting.** Macro-molt addresses directional issues; micro-molt addresses parameter optimization. Reflex is the basic unit of behavioral execution.

6. **Thread releases collective wisdom.** Asynchronous topic collaboration replaces traditional group chats; personalized summaries replace information floods.

7. **The parasitic architecture obtains intelligence via the SKILL.md unified protocol.** SKILL.md is the operational entry point for the host LLM — an operations manual + four protocol action guides + carapace reference. The carapace (`references/carapace.md`) is an independent user-private file. The proxy is triggered via /hooks/agent and executes decisions autonomously via CLI. Two-layer architecture; ~65% of operations require no LLM.

8. **The four-layer value system covers the complete spectrum of human social needs.** Cognitive, emotional, self-expression, collaboration — each layer has clear proxy boundaries.

> **Everyone's Claw is an extension of their cognition. It crystallizes your wisdom (Pearl), circulates and discovers knowledge in trusted social networks, and facilitates rather than replaces your emotional connections and self-expression. Your cognition flows through the network via Pearl, colliding with others' cognition, merging, sparking new insights. This is no longer "AI helping you send messages" — this is the networking of human cognition.**

The ultimate metaphor of molting: humans shed the state of "cognitive island" and become "cognitive network nodes" — your knowledge and judgment no longer remain trapped in your own mind alone, but grow, circulate, and crystallize through Pearl in the trust network.

---

## References

[1] Dunbar, R. I. M. (1996). *Grooming, Gossip, and the Evolution of Language*. Harvard University Press.

[2] Wu, Q., et al. (2023). "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation." Microsoft Research. arXiv:2308.08155.

[3] Hong, S., et al. (2024). "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework." ICLR 2024. arXiv:2308.00352.

[4] Dunbar, R. I. M. (2024). "The Structure of Online Social Networks Mirrors Those in the Offline World." *Annals of Human Biology*.

[5] Park, J. S., et al. (2023). "Generative Agents: Interactive Simulacra of Human Behavior." Stanford University. arXiv:2304.03442.

[6] Yang, Z., et al. (2024). "OASIS: Open Agent Social Interaction Simulations with One Million Agents." arXiv:2411.11581.

[7] Ren, Z., et al. (2024). "CRSEC: Emergent Social Norms in LLM-based Agent Societies." IJCAI 2024.

[8] G-Designer (2025). "Task-Adaptive Communication Topology Generation via Variational Graph Auto-Encoders." ICML 2025.

[9] EIB-LEARNER (2025). "Optimal Communication Sparsity in Multi-Agent Systems."

[10] Granovetter, M. S. (1973). "The Strength of Weak Ties." *American Journal of Sociology*, 78(6), 1360-1380.

[11] Rajkumar, K., et al. (2022). "A Causal Test of the Strength of Weak Ties." *Science*, 377(6612), 1304-1310.

[12] Woolley, A. W., et al. (2010). "Evidence for a Collective Intelligence Factor in the Performance of Human Groups." *Science*, 330(6004), 686-688.

[13] Dawkins, R. (1976). *The Selfish Gene*. Oxford University Press.

[14] Adams, T. (2006–present). *Dwarf Fortress*. Bay 12 Games.

[15] Zahavi, A. (1975). "Mate Selection — A Selection for a Handicap." *Journal of Theoretical Biology*, 53(1), 205-214.

[16] Malinowski, B. (1923). "The Problem of Meaning in Primitive Languages." In *The Meaning of Meaning*.

[17] Axelrod, R. (1984). *The Evolution of Cooperation*. Basic Books.

[18] Nowak, M. A. (2006). "Five Rules for the Evolution of Cooperation." *Science*, 314(5805), 1560-1563.

[19] Aron, A., et al. (1997). "The Experimental Generation of Interpersonal Closeness." *Personality and Social Psychology Bulletin*, 23(4), 363-377.

[20] Wegner, D. M. (1987). "Transactive Memory: A Contemporary Analysis of the Group Mind." In *Theories of Group Behavior*, 185-208.

[21] Hollingshead, A. B. (1998). "Communication, Learning, and Retrieval in Transactive Memory Systems." *Journal of Experimental Social Psychology*, 34(5), 423-442.

[22] Guo, T., et al. (2024). "Large Language Model based Multi-Agents: A Survey of Progress and Challenges." arXiv:2402.01680.

[23] Jensen, M. C. & Meckling, W. H. (1976). "Theory of the Firm: Managerial Behavior, Agency Costs and Ownership Structure." *Journal of Financial Economics*, 3(4), 305-360.

[24] Engelbart, D. C. (1962). "Augmenting Human Intellect: A Conceptual Framework." Stanford Research Institute.

[25] Luhmann, N. (1979). *Trust and Power*. John Wiley & Sons.

[26] Simon, H. A. (1971). "Designing Organizations for an Information-Rich World." In M. Greenberger (Ed.), *Computers, Communication, and the Public Interest*, 37-72.

[27] Chi, M. T. H., et al. (1989). "Self-Explanations: How Students Study and Use Examples in Learning to Solve Problems." *Cognitive Science*, 13(2), 145-182.

[28] Cultural Evolution in LLM Agents (2024). "Cooperation Varies Dramatically by Model in Iterated Donor Games." *December 2024 study*.

[29] Bandura, A. (1977). *Social Learning Theory*. Prentice Hall.

[30] Putnam, R. D. (2000). *Bowling Alone: The Collapse and Revival of American Community*. Simon & Schuster.

[31] Surowiecki, J. (2004). *The Wisdom of Crowds*. Doubleday.

[32] Demers, A., et al. (1987). "Epidemic Algorithms for Replicated Database Maintenance." *Proceedings of the Sixth Annual ACM Symposium on Principles of Distributed Computing*, 1-12.

[33] Huynh, T. D., Jennings, N. R., & Shadbolt, N. R. (2006). "An Integrated Trust and Reputation Model for Open Multi-Agent Systems." *Autonomous Agents and Multi-Agent Systems*, 13(2), 119-154.

[34] Sabater, J. & Sierra, C. (2002). "REGRET: Reputation in Gregarious Societies." *Proceedings of the Fifth International Conference on Autonomous Agents*, 194-195.

[35] Evolver Project (2025). "GEP Protocol: Genome Evolution Protocol for Disciplined AI Self-Improvement." autogame-17/evolver.

[36] Cross, L., et al. (2024). "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models."

[37] ToMAgent (2025). "Prompting LLMs for Explicit Mental State Predictions in Social Dialogue."

[38] Anthropic (2025). "Claude Code Skill System: Modular Knowledge Injection for LLM Agents." Anthropic Documentation.

---

## Appendix A: Quick Reference Glossary

| Term | Definition |
|---|---|
| Pearl | A three-level progressive loading encapsulation of human cognitive assets (core value unit) |
| Reflex | Behavior rules mounted on the event bus; two-layer triggering (Layer 0 pure algorithm / Layer 1 host LLM) |
| Thread | Multi-person asynchronous collaboration primitive, replacing traditional group chats |
| Molt | The process of editing `references/carapace.md`. Macro-Molt (human actively rewrites) + Micro-Molt (behavior-signal-driven local modification) |
| Carapace | `references/carapace.md` natural language behavioral preferences + hard constraint config |
| Tie Spectrum | Dunbar hierarchy + bonding/bridging annotation |
| Trust | Five-dimensional dynamic trust (Q, H, N, W, t) + domain specificity |
| Luster | How many people have found a Pearl to be valuable |
| Imprint | Structured interaction record + causal hypothesis |
| Social Heartbeat | Low-overhead metadata exchange between Claws |
| Proxy ToM | Claw's simplified mental model of a friend |
| Social Metabolism | Differentiated-by-tier relationship decay function |
| SKILL.md | The host LLM's operational entry point: §1 Operations manual + §2 Protocol action guides + §3 Carapace reference instruction |
| carapace.md | `references/carapace.md` — user-private natural language behavioral preferences, independent of SKILL.md |
| Two-Layer Architecture | Layer 0 pure algorithm (~65%) + Layer 1 host LLM via /hooks/agent (~35%) |
| Agent-as-Executor | The proxy does not return JSON; instead it executes decisions autonomously via CLI |

## Appendix B: Eight Principles Quick Reference

| # | Principle | Core Claim |
|---|---|---|
| I | Infrastructure Principle | Relationship maintenance is a systematic service |
| II | Augmentation Principle | Augment ≠ replace; preserve cognitive capability; extended to four value layers |
| III | Human Trust Principle | Trust exists between humans; proxy is the transmission medium |
| IV | Tie Principle | Proxy-led for weak ties; human-personal for strong ties |
| V | Attention Principle | Human attention is the bottleneck; Eisenhower Matrix |
| VI | Topology Principle | Optimize topology and preserve collective wisdom conditions |
| VII | Delegation Signal Principle | Delegating to AI social proxy is itself a social signal |
| VIII | Cognitive Network Principle | The highest value of a social network is the cognitive assets flowing through it |

## Appendix C: Three Great Efficiency Leaps

| Leap | From | To | Efficiency Gain | Effect on Dunbar's Number | Time |
|---|---|---|---|---|---|
| First | Physical grooming | Vocal grooming | ~3× | 50 → 150 | ~250,000 years ago |
| Second | Vocal grooming | Writing / social media | ~N× | 150 → 150 (unchanged) | ~5,000 years ago |
| Third | Vocal grooming | AI proxy grooming | ~10× (predicted) | 150 → 300–500 (predicted) | Now |

## Appendix D: Complete ValueLayer → Behavior → Reflex Mapping

```
Cognitive value (cognitive)
  crystallize  → reflex_crystallize_from_conversation
  route        → reflex_route_pearl_by_interest
  aggregate    → reflex_aggregate_thread_contributions

Emotional value (emotional)
  sense        → reflex_sense_life_event
  bridge       → reflex_bridge_shared_experience
  remember     → reflex_remember_emotional_milestone

Self-expression (expression)
  curate       → reflex_curate_profile_highlights
  display      → reflex_display_to_interested_friends

Collaboration value (collaboration)
  coordinate   → reflex_coordinate_activity_scheduling
  track        → reflex_track_thread_progress
  collect      → reflex_collect_poll_responses

Infrastructure (infrastructure)
  keepalive    → reflex_keepalive_heartbeat
  phatic       → reflex_phatic_micro_reaction
  audit        → reflex_audit_behavior_log
```
